{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joan947/mini_LLM/blob/main/flops_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtQYMbLvgzO-"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
        "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbrESHKtgzPA"
      },
      "source": [
        "# FLOPS Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS2WjniMgzPB"
      },
      "source": [
        "- FLOPs (Floating Point Operations Per Second) measure the computational complexity of neural network models by counting the number of floating-point operations executed\n",
        "- High FLOPs indicate more intensive computation and energy consumption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L01-NzkggzPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38edd0c6-d26b-4f1e-97f4-fcd4ca9d2d47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from thop) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->thop) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->thop) (3.0.3)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n"
          ]
        }
      ],
      "source": [
        "# pip install -r requirements-extra.txt\n",
        "!pip install thop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObzfVatqgzPC",
        "outputId": "879ad013-6595-4133-c5ed-d502ae389aee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thop version: 0.1.1-2209072238\n",
            "torch version: 2.8.0+cu126\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\n",
        "    \"thop\",\n",
        "    \"torch\",\n",
        "]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74UpjSLjgzPC"
      },
      "source": [
        "&nbsp;\n",
        "# Simple benchmark with fixed batch size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/rasbt/LLMs-from-scratch.git\n"
      ],
      "metadata": {
        "id": "J7PqF73P-eQy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llms-from-scratch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PncDtgVC_jjB",
        "outputId": "bf8e36ed-4054-401c-b2f0-e690240613d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llms-from-scratch\n",
            "  Downloading llms_from_scratch-1.0.19-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: torch>=2.2.2 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (2.8.0+cu126)\n",
            "Requirement already satisfied: tensorflow>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (2.19.0)\n",
            "Collecting jupyterlab>=4.0 (from llms-from-scratch)\n",
            "  Downloading jupyterlab-4.4.9-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (0.12.0)\n",
            "Requirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (3.10.0)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (4.67.1)\n",
            "Requirement already satisfied: numpy<2.1,>=1.26 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.2.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (2.2.2)\n",
            "Collecting pip>=25.0.1 (from llms-from-scratch)\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: pytest>=8.3.5 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (8.4.2)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (0.28.1)\n",
            "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (6.17.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (5.8.1)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (2.14.0)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (25.0)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (75.2.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (6.4.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (5.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.1->llms-from-scratch) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.1->llms-from-scratch) (2025.2)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.5->llms-from-scratch) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.5->llms-from-scratch) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.5->llms-from-scratch) (2.19.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (2.32.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.5.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.5.1->llms-from-scratch) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (3.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=2.18.0->llms-from-scratch) (0.45.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (0.16.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (26.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.0.3->jupyterlab>=4.0->llms-from-scratch) (3.0.3)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (25.1.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.5.3)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (5.10.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.23.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core->jupyterlab>=4.0->llms-from-scratch) (4.5.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (4.25.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.18.0->llms-from-scratch) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.18.0->llms-from-scratch) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.2.2->llms-from-scratch) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->llms-from-scratch) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->llms-from-scratch) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->llms-from-scratch) (3.1.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (25.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (3.0.52)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (0.27.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.4)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.21.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.12/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (4.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.8.5)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (24.11.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.2.14)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.23)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.3.0)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.9.0.20251008)\n",
            "Downloading llms_from_scratch-1.0.19-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.3/83.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.4.9-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m136.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip, json5, jedi, async-lru, jupyterlab-server, jupyter-lsp, jupyterlab, llms-from-scratch\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed async-lru-2.0.5 jedi-0.19.2 json5-0.12.1 jupyter-lsp-2.3.0 jupyterlab-4.4.9 jupyterlab-server-2.27.3 llms-from-scratch-1.0.19 pip-25.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90pnCK39gzPD"
      },
      "source": [
        "- forward pass only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GerIdRMXd6g9",
        "outputId": "5eea666b-c894-432e-a10c-62626948cbb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-medium (355M) : 1.4e+12 FLOPS\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from thop import profile\n",
        "\n",
        "# For installation instructions, see:\n",
        "# https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
        "from llms_from_scratch.ch04 import GPTModel\n",
        "\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "# model_configs = {\n",
        "#     \"gpt-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "#     \"gpt-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "#     \"gpt-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "#     \"gpt-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "# }\n",
        "\n",
        "model_configs = {\n",
        "\n",
        "    \"gpt-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "}\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 2\n",
        "input_tensor = torch.randint(0, 50257, (batch_size, 1024)).to(device)\n",
        "\n",
        "for size in model_configs:\n",
        "    BASE_CONFIG.update(model_configs[size])\n",
        "\n",
        "    model = GPTModel(BASE_CONFIG).bfloat16()\n",
        "    model.to(device)\n",
        "\n",
        "    # MACS = multiply-accumulate operations\n",
        "    # MACS are typically counted as two FLOPS (one multiply and one accumulate)\n",
        "    macs, params = profile(model, inputs=(input_tensor,), verbose=False)\n",
        "    flops = 2*macs\n",
        "    print(f\"{size:18}: {flops:.1e} FLOPS\")\n",
        "\n",
        "    del model\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S6V05QmgzPD"
      },
      "source": [
        "&nbsp;\n",
        "# Simple benchmark with automatic batch size finding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amw4E983gzPD"
      },
      "source": [
        "- forward pass only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h08VOiqpgzPE",
        "outputId": "7a2768ca-c954-4558-9077-ff0ad9415bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing gpt-medium (355M)\n",
            "  Batch size 512: 3.7e+14 FLOPS\n",
            "  Batch size 528: 3.8e+14 FLOPS\n",
            "  Batch size 536: 3.9e+14 FLOPS\n",
            "  Batch size 540: 3.9e+14 FLOPS\n",
            "  Batch size 542: 3.9e+14 FLOPS\n",
            "  Batch size 543: 3.9e+14 FLOPS\n"
          ]
        }
      ],
      "source": [
        "for size in model_configs:\n",
        "    print(f\"\\nProcessing {size}\")\n",
        "    config = BASE_CONFIG.copy()\n",
        "    config.update(model_configs[size])\n",
        "\n",
        "    min_batch_size = 1\n",
        "    max_batch_size = None\n",
        "    max_possible_batch_size = 4096\n",
        "\n",
        "    while min_batch_size <= max_possible_batch_size:\n",
        "        batch_size = (min_batch_size + max_possible_batch_size) // 2\n",
        "        try:\n",
        "            input_tensor = torch.randint(\n",
        "                0, config[\"vocab_size\"],\n",
        "                (batch_size, config[\"context_length\"]),\n",
        "                device=device\n",
        "            )\n",
        "\n",
        "            model = GPTModel(config).bfloat16().to(device)\n",
        "\n",
        "            # MACS = multiply-accumulate operations\n",
        "            # MACS are typically counted as two FLOPS (one multiply and one accumulate)\n",
        "            macs, params = profile(model, inputs=(input_tensor,), verbose=False)\n",
        "            flops = 2 * macs\n",
        "            print(f\"  Batch size {batch_size}: {flops:.1e} FLOPS\")\n",
        "\n",
        "            # If successful, try a larger batch size\n",
        "            min_batch_size = batch_size + 1\n",
        "            max_batch_size = batch_size\n",
        "\n",
        "            # Clean up\n",
        "            del model, input_tensor\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            if \"out of memory\" in str(e):\n",
        "                # Try smaller batch size\n",
        "                max_possible_batch_size = batch_size - 1\n",
        "\n",
        "                # Clean up\n",
        "                try:\n",
        "                    del model, input_tensor\n",
        "                    torch.cuda.empty_cache()\n",
        "                except NameError:\n",
        "                    pass\n",
        "            else:\n",
        "                raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4lD7tfcgzPE"
      },
      "source": [
        "&nbsp;\n",
        "# Benchmark with automatic batch size finding and Model FLOP Utilization (MFU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70Y2mblVgzPE"
      },
      "source": [
        "- Model FLOPs Utilization (MFU) explanation from the [PaLM paper](https://arxiv.org/abs/2204.02311)\n",
        "\n",
        "> We propose a new metric for efficiency that is implementation-independent and permits a cleaner comparison of system efficiency, called model FLOPs utilization (MFU). This is the ratio of the observed throughput (tokens-per-second) relative to the theoretical maximum throughput of a system operating at peak FLOPs. Crucially, the “theoretical maximum” throughput only accounts for the required operations to compute the forward+backward passes, and not rematerialization.\n",
        "\n",
        "\n",
        "$$\\text{MFU} = \\frac{\\text{Observed Tokens per Second}}{\\text{Theoretical Max Tokens per Second}}$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\\text{Theoretical Max Tokens per Second} = \\frac{\\text{Max FLOPs per Second}}{\\text{Total FLOPs per Token}}$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\\text{Tokens per Second} = \\frac{\\text{Batch Size} \\times \\text{Sequence Length}}{\\text{Total Time}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKttjC8xgzPF"
      },
      "source": [
        "- forward and backward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6aO4rjtNgzPF"
      },
      "outputs": [],
      "source": [
        "# Theoretical max flops per second provided by the GPU manufacturer\n",
        "\n",
        "flops_per_second = {\n",
        "    # https://www.techpowerup.com/gpu-specs/h100-pcie-80-gb.c3899\n",
        "    \"H100\": {\n",
        "        torch.float32: 51.22e12,  # 51.22 TFLOPs for FP32 on NVIDIA H100\n",
        "        torch.float16: 204.9e12,  # 204.9 TFLOPs for FP16 on NVIDIA H100\n",
        "        torch.bfloat16: 204.9e12\n",
        "    },\n",
        "    # https://www.techpowerup.com/gpu-specs/l4.c4091\n",
        "    \"L4\": {\n",
        "        torch.float32: 30.29e12,  # 30.29 TFLOPs for FP32 on NVIDIA L4\n",
        "        torch.float16: 30.29e12,  # 30.29 TFLOPs for FP16 on NVIDIA L4\n",
        "        torch.bfloat16: 30.29e12\n",
        "    },\n",
        "    # https://www.techpowerup.com/gpu-specs/tesla-t4.c3316\n",
        "    \"T4\": {\n",
        "        torch.float32: 8.1e12,  # 8.1 TFLOPs for FP32 on NVIDIA T4\n",
        "        torch.float16: 65.13e12,  # 65.13 TFLOPs for FP16 on NVIDIA T4\n",
        "        torch.bfloat16: 65.13e12\n",
        "    },\n",
        "    # https://www.techpowerup.com/gpu-specs/a10g.c3798\n",
        "    \"A10G\": {\n",
        "        torch.float32: 31.52e12,  # 31.52 TFLOPs for FP32 on NVIDIA A10G\n",
        "        torch.float16: 31.52e12,  # 31.52 TFLOPs for FP16 on NVIDIA A10G\n",
        "        torch.bfloat16: 31.52e12\n",
        "    },\n",
        "    # https://www.techpowerup.com/gpu-specs/a100-pcie-40-gb.c3623\n",
        "    \"A100\": {\n",
        "        torch.float32: 19.49e12,  # 19.49 TFLOPs for FP32 on NVIDIA A100\n",
        "        torch.float16: 77.97e12,  # 77.97 TFLOPs for FP16 on NVIDIA A100\n",
        "        torch.bfloat16: 77.97e12\n",
        "    },\n",
        "    # https://www.techpowerup.com/gpu-specs/geforce-rtx-3080.c3621\n",
        "    \"RTX_3080\": {\n",
        "        torch.float32: 29.77e12,  # 29.77 TFLOPs for FP32 on NVIDIA RTX 3080\n",
        "        torch.float16: 29.77e12,  # 29.77 TFLOPs for FP16 on NVIDIA RTX 3080\n",
        "        torch.bfloat16: 29.77e12\n",
        "    },\n",
        "    # https://www.techpowerup.com/gpu-specs/geforce-rtx-3090.c3622\n",
        "    \"RTX_3090\": {\n",
        "        torch.float32: 35.58e12,  # 35.58 TFLOPs for FP32 on NVIDIA RTX 3090\n",
        "        torch.float16: 35.58e12,  # 35.58 TFLOPs for FP16 on NVIDIA RTX 3090\n",
        "        torch.bfloat16: 35.58e12\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW5qWfE7gzPF",
        "outputId": "01466794-2a39-4402-c802-2a3fb0764109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Model: A100\n",
            "\n",
            "Processing gpt-medium (355M)\n",
            "  Batch size 16: Tokens/sec: 22133.69, MFU: 0.6020\n",
            "  Batch size 24: Tokens/sec: 26962.52, MFU: 0.7334\n",
            "  Batch size 28: Tokens/sec: 27224.30, MFU: 0.7405\n",
            "  Batch size 30: Tokens/sec: 27738.19, MFU: 0.7545\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def get_gpu_model(flops_per_second_dict):\n",
        "    device_name = torch.cuda.get_device_name(0)\n",
        "    for model in flops_per_second_dict.keys():\n",
        "        if model in device_name:\n",
        "            return model\n",
        "    return \"Unknown\"  # Default if no matching model is found\n",
        "\n",
        "\n",
        "gpu_model = get_gpu_model(flops_per_second)\n",
        "print(\"GPU Model:\", gpu_model)\n",
        "\n",
        "if gpu_model != \"Unknown\":\n",
        "\n",
        "    for size in model_configs:\n",
        "        print(f\"\\nProcessing {size}\")\n",
        "        config = BASE_CONFIG.copy()\n",
        "        config.update(model_configs[size])\n",
        "\n",
        "        min_batch_size = 1\n",
        "        max_batch_size = None\n",
        "        max_possible_batch_size = 4096\n",
        "\n",
        "        while min_batch_size <= max_possible_batch_size:\n",
        "            batch_size = (min_batch_size + max_possible_batch_size) // 2\n",
        "            try:\n",
        "                input_tensor = torch.randint(\n",
        "                    0, config[\"vocab_size\"],\n",
        "                    (batch_size, config[\"context_length\"]),\n",
        "                    device=device\n",
        "                )\n",
        "\n",
        "                model = GPTModel(config).bfloat16().to(device)\n",
        "                model.train()\n",
        "\n",
        "                # Start timing\n",
        "                torch.cuda.synchronize()\n",
        "                start_time = time.time()\n",
        "\n",
        "                # Forward & backward pass\n",
        "                output = model(input_tensor)\n",
        "                loss = output.sum()  # Compute a dummy loss\n",
        "                loss.backward()\n",
        "\n",
        "                # End timing\n",
        "                torch.cuda.synchronize()\n",
        "                end_time = time.time()\n",
        "\n",
        "                total_time_seconds = end_time - start_time\n",
        "\n",
        "                # Calculate FLOPs for forward pass\n",
        "                macs, params = profile(model, inputs=(input_tensor,), verbose=False)\n",
        "                flops_forward = 2 * macs  # Assuming one MAC equals two FLOPs\n",
        "\n",
        "                # Estimate FLOPs for backward pass (typically 2x forward FLOPs)\n",
        "                flops_backward = 2 * flops_forward\n",
        "\n",
        "                # Total FLOPs for forward + backward passes\n",
        "                total_flops = flops_forward + flops_backward  # Or total_flops = flops_forward * 3\n",
        "\n",
        "                data_type = next(model.parameters()).dtype\n",
        "                max_flops_per_second = flops_per_second[gpu_model].get(data_type, 0)\n",
        "\n",
        "                # Compute tokens per second\n",
        "                tokens_processed = batch_size * config[\"context_length\"]\n",
        "                tokens_per_second = tokens_processed / total_time_seconds\n",
        "\n",
        "                # Compute FLOPs per token\n",
        "                flops_per_token = total_flops / tokens_processed\n",
        "\n",
        "                # Compute theoretical max tokens per second\n",
        "                if flops_per_token > 0:\n",
        "                    theoretical_max_tokens_per_second = max_flops_per_second / flops_per_token\n",
        "                else:\n",
        "                    theoretical_max_tokens_per_second = 0  # Avoid division by zero\n",
        "\n",
        "                # Compute MFU\n",
        "                if theoretical_max_tokens_per_second > 0:\n",
        "                    mfu = tokens_per_second / theoretical_max_tokens_per_second\n",
        "                else:\n",
        "                    mfu = 0  # Avoid division by zero\n",
        "\n",
        "                print(f\"  Batch size {batch_size}: Tokens/sec: {tokens_per_second:.2f}, MFU: {mfu:.4f}\")\n",
        "\n",
        "                # If successful, try a larger batch size\n",
        "                min_batch_size = batch_size + 1\n",
        "                max_batch_size = batch_size\n",
        "\n",
        "                # Clean up\n",
        "                del model, input_tensor, output, loss\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e).lower():\n",
        "                    # Try smaller batch size\n",
        "                    max_possible_batch_size = batch_size - 1\n",
        "\n",
        "                    # Clean up\n",
        "                    try:\n",
        "                        del model, input_tensor\n",
        "                        torch.cuda.empty_cache()\n",
        "                    except NameError:\n",
        "                        pass\n",
        "                else:\n",
        "                    raise e\n",
        "\n",
        "else:\n",
        "    print(\"Unknown GPU model. Please update the flops_per_second dictionary with your GPU information.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LovmswRigzPG"
      },
      "source": [
        "- a value of 1.0 is best (equal to 100%)\n",
        "- Note that the batch sizes are smaller than previously because we also carry out the backward pass here, which is more memory-intensive"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}